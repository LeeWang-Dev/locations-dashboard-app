// aws rds db info
hosting:lee-instance.ciuz5stfwmcj.us-east-1.rds.amazonaws.com
port:5432
db:locations_db
user:leewang
password:testing1234

CREATE EXTENSION postgis;

CREATE EXTENSION aws_s3 CASCADE;

// create table with a date

CREATE TABLE public.locations_2021_08_01
(
    id bigint NOT NULL GENERATED ALWAYS AS IDENTITY ( INCREMENT 1 START 1 MINVALUE 1 MAXVALUE 9223372036854775807 CACHE 1 ),
    advertiser_id character varying(50) COLLATE pg_catalog."default",
    platform character varying(10) COLLATE pg_catalog."default",
    location_at bigint,
    latitude double precision,
    longitude double precision,
    geom geometry,
    altitude double precision,
    horizontal_accuracy double precision,
    vertical_accuracy double precision,
    heading double precision,
    speed double precision,
    ip_4 character varying(20) COLLATE pg_catalog."default",
    ip_6 character varying(50) COLLATE pg_catalog."default",
    final_country character varying(2) COLLATE pg_catalog."default",
    user_agent character varying(500) COLLATE pg_catalog."default",
    background smallint,
    publisher_id character varying(50) COLLATE pg_catalog."default",
    wifi_ssid character varying(50) COLLATE pg_catalog."default",
    wifi_bssid character varying(100) COLLATE pg_catalog."default",
    tech_signals text COLLATE pg_catalog."default",
    carrider character varying(100) COLLATE pg_catalog."default",
    device_model character varying(50) COLLATE pg_catalog."default",
    venu_name character varying(200) COLLATE pg_catalog."default",
    venu_category character varying(200) COLLATE pg_catalog."default",
    dwell_time character varying(20) COLLATE pg_catalog."default",
    CONSTRAINT "locations_2021_08_01_pkey" PRIMARY KEY (id)
)

// download csv data from s3-bucket
// split csv files with 1M rows from a large csv file
// check csv records for validated fields
// upload csv files on s3-bucket
// import csv data to db from s3-bucket

SELECT aws_s3.table_import_from_s3 (
  'public.locations_2021_08_01',
  'advertiser_id,
   platform,
   location_at,
   latitude,
   longitude,
   altitude,
   horizontal_accuracy,
   vertical_accuracy,
   heading,
   speed,
   ip_4,
   ip_6,
   final_country,
   user_agent,
   background,
   publisher_id,
   wifi_ssid,
   wifi_bssid,
   tech_signals,
   carrider,
   device_model,
   venu_name,
   venu_category,
   dwell_time',
  '(FORMAT csv, HEADER true, DELIMITER '','', QUOTE ''"'', ESCAPE ''\'')',
  'lee-data',
  '2021-08-01/part-00000-db968283-5852-4503-810b-37556393f919-c000_0.csv',
  'us-east-1',
  'AKIATPAJQC2YFZG4X6HV',
  'oq/tB601JS600kV1UG2HFhlu9gUiJfEPhlL+Iva6'
);

SELECT aws_s3.table_import_from_s3 (
  'public.locations_import_test',
  'advertiser_id,
   platform,
   location_at,
   latitude,
   longitude,
   altitude,
   horizontal_accuracy,
   vertical_accuracy,
   heading,
   speed,
   ip_4,
   ip_6,
   final_country,
   device_model',
  '(FORMAT csv, HEADER false, DELIMITER '','', QUOTE ''"'', ESCAPE ''\'')',
  'lee-data',
  '2021-08-01/part-00000-db968283-5852-4503-810b-37556393f919-c000_1.csv',
  'us-east-1',
  'AKIATPAJQC2YFZG4X6HV',
  'oq/tB601JS600kV1UG2HFhlu9gUiJfEPhlL+Iva6'
);

// add geom field in the table.

// add geometry

UPDATE
 locations_2021_08_01
SET
 geom = ST_SetSRID(ST_MakePoint(longitude, latitude), 4326)
WHERE
 geom IS NULL

// create indexes
// create index geom_idx on locations_2021_08_01 using gist(geom)
// create index advertiser_id_idx on locations_2021_08_01 using btree(advertiser_id)
// platform, location_at


